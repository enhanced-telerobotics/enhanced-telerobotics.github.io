<!doctype html><html class="no-js" lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Research</title><link rel="stylesheet" type="text/css" href="https://enhanced-telerobotics.github.io/assets/css/styles_feeling_responsive.css"> <script src="https://enhanced-telerobotics.github.io/assets/js/modernizr.min.js"></script> <script src="https://ajax.googleapis.com/ajax/libs/webfont/1.5.18/webfont.js"></script> <script> WebFont.load({ google: { families: [ 'Lato:400,700,400italic:latin', 'Volkhov::latin' ] } }); </script> <noscript><link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic%7CVolkhov' rel='stylesheet' type='text/css'> </noscript><meta name="description" content="Enhanced teleRobotic Interfaces and Experiences Lab at Case Western Reserve University"><meta name="robots" content="noindex"><link rel="canonical" href="https://enhanced-telerobotics.github.io/research-list/"><meta property="og:title" content="Research"><meta property="og:description" content="Enhanced teleRobotic Interfaces and Experiences Lab at Case Western Reserve University"><meta property="og:url" content="https://enhanced-telerobotics.github.io/research-list/"><meta property="og:locale" content="en_EN"><meta property="og:type" content="website"><meta property="og:site_name" content="ERIE Lab at CWRU"><link type="text/plain" rel="author" href="https://enhanced-telerobotics.github.io/humans.txt"><link rel="icon" sizes="32x32" href="https://enhanced-telerobotics.github.io/assets/img/favicon-32x32.png"><link rel="icon" sizes="192x192" href="https://enhanced-telerobotics.github.io/assets/img/touch-icon-192x192.png"><link rel="apple-touch-icon-precomposed" sizes="180x180" href="https://enhanced-telerobotics.github.io/assets/img/apple-touch-icon-180x180-precomposed.png"><link rel="apple-touch-icon-precomposed" sizes="152x152" href="https://enhanced-telerobotics.github.io/assets/img/apple-touch-icon-152x152-precomposed.png"><link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://enhanced-telerobotics.github.io/assets/img/apple-touch-icon-144x144-precomposed.png"><link rel="apple-touch-icon-precomposed" sizes="120x120" href="https://enhanced-telerobotics.github.io/assets/img/apple-touch-icon-120x120-precomposed.png"><link rel="apple-touch-icon-precomposed" sizes="114x114" href="https://enhanced-telerobotics.github.io/assets/img/apple-touch-icon-114x114-precomposed.png"><link rel="apple-touch-icon-precomposed" sizes="76x76" href="https://enhanced-telerobotics.github.io/assets/img/apple-touch-icon-76x76-precomposed.png"><link rel="apple-touch-icon-precomposed" sizes="72x72" href="https://enhanced-telerobotics.github.io/assets/img/apple-touch-icon-72x72-precomposed.png"><link rel="apple-touch-icon-precomposed" href="https://enhanced-telerobotics.github.io/assets/img/apple-touch-icon-precomposed.png"><meta name="msapplication-TileImage" content="https://enhanced-telerobotics.github.io/assets/img/msapplication_tileimage.png"><meta name="msapplication-TileColor" content="#fabb00"> <script async src="https://www.googletagmanager.com/gtag/js?id=G-N5Y5DWZZGV"></script> <script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-N5Y5DWZZGV'); </script><body id="top-of-page" class="blog-index"><div id="navigation" class="sticky"><nav class="top-bar" role="navigation" data-topbar data-options="scrolltop: false"><ul class="title-area"><li class="name"><h1 class="hide-for-large-up"><a href="https://enhanced-telerobotics.github.io"> ERIE Lab at CWRU</a></h1><li class="toggle-topbar toggle-topbar-click menu-icon"><a><span>Nav</span></a></ul><section class="top-bar-section"><ul class="left"><li><a href="https://enhanced-telerobotics.github.io/">Home</a><li class="divider"><li><a href="https://enhanced-telerobotics.github.io/team/">Team</a><li class="divider"><li class="active"><a href="https://enhanced-telerobotics.github.io/research-list/">Research</a><li class="divider"><li><a href="https://enhanced-telerobotics.github.io/publications/">Publications</a><li class="divider"><li class="has-dropdown"> <a href="https://enhanced-telerobotics.github.io/teaching/">Teaching</a><ul class="dropdown"><li><a href="https://enhanced-telerobotics.github.io/ECSE600/">ECSE600</a></ul><li class="divider"><li class="has-dropdown"> <a href="https://enhanced-telerobotics.github.io/news/">News</a><ul class="dropdown"><li><a href="https://enhanced-telerobotics.github.io/news/archive/">Archive</a></ul><li class="divider"></ul><ul class="right"><li class="divider"><li><a href="https://enhanced-telerobotics.github.io/contact/">Contact</a></ul></section></nav></div><div id="masthead-no-image-header"><div class="row"><div class="small-12 columns"> <a id="logo" href="https://enhanced-telerobotics.github.io/" title="ERIE Lab at CWRU – Enhanced teleRobotic Interfaces at CWRU"> <img src="https://enhanced-telerobotics.github.io/assets/img/logo.png" alt="ERIE Lab at CWRU – Enhanced teleRobotic Interfaces at CWRU"> </a></div></div></div><div class="row t30"><div class="medium-12 columns"><article><header><h1>Research</h1></header><div class="row"><div class="medium-12 columns"><div class="row"><div class="small-12 columns b60"><h2><a href="https://enhanced-telerobotics.github.io/research/HapticError/">Haptic Feedback for Motor Learning</a></h2><p> <a href="https://enhanced-telerobotics.github.io/research/HapticError/" title="Haptic Feedback for Motor Learning"><img src="/images/Finger.png" class="alignleft" width="300" height="300" alt="Research"></a> Much like how a tennis or golf coach can grasp your arm and haptically show you how to swing your arms to execute a shot, haptic systems can be programmed to do the same. We investigate how humans learn from haptic feedback and design methods to intelligently deliver this instruction through robotic systems. <a href="https://enhanced-telerobotics.github.io/research/HapticError/" title="Read Haptic Feedback for Motor Learning"><strong>Read More&nbsp;›</strong></a></div></div><div class="row"><div class="small-12 columns b60"><h2><a href="https://enhanced-telerobotics.github.io/research/OpenSourceForceSensor/">Open Source Force Sensors for Minimally Invasive Surgical Robotics Research</a></h2><p> <a href="https://enhanced-telerobotics.github.io/research/OpenSourceForceSensor/" title="Open Source Force Sensors for Minimally Invasive Surgical Robotics Research"><img src="/images/force_sensor_thumb.jpg" class="alignleft" width="300" height="300" alt="Research"></a> Research into haptic feedback, data-driven indirect force sensing approaches, and surgical skill evaluation require accurate knowledge of tool-tissue interaction forces. However, such measurement tools are not available commercially, and are difficult to realize without specialized knowledge. Our group develops sensor designs that strike a balance between ease-of-manufacture, cost, size and accuracy, to help researchers achieve their vision, thereby helping to advance our field. Our force sensors use an array of miniature commercially available load cells to sense forces applied to the forcep jaws. The interface to different forcep jaws are compatible with different jaw geometries making the system customizable to different surgical applications. The range of the for sensor is 5N in axial compression, and tension and 3N in the positive and negative lateral directions. <a href="https://enhanced-telerobotics.github.io/research/OpenSourceForceSensor/" title="Read Open Source Force Sensors for Minimally Invasive Surgical Robotics Research"><strong>Read More&nbsp;›</strong></a></div></div><div class="row"><div class="small-12 columns b60"><h2><a href="https://enhanced-telerobotics.github.io/research/NNForceEstimation/">Vision-based Force Estimation and Haptic Feedback using Neural Networks</a></h2><p> <a href="https://enhanced-telerobotics.github.io/research/NNForceEstimation/" title="Vision-based Force Estimation and Haptic Feedback using Neural Networks"><img src="/images/nn_force_est_thumb.png" class="alignleft" width="300" height="300" alt="Research"></a> Forcep tip force sensing in robot-assisted minimally invasive surgery is challenging due to strict requirements for miniaturization, biocompatibility, and sterilizability. Indirect force estimation is a promising method to measure forces while circumventing these constraints. Much like how humans can estimate forces visually, neural networks can attempt to do something similar. However, there are concerns as to the generalizability of these methods as well as the relative importance of visual information compared to robot kinematic state information as inputs. We characterize the performance of vision-based neural networks with these considerations in mind and quantify the quality of the closed-loop haptic feedback they can provide to the operator. <a href="https://enhanced-telerobotics.github.io/research/NNForceEstimation/" title="Read Vision-based Force Estimation and Haptic Feedback using Neural Networks"><strong>Read More&nbsp;›</strong></a></div></div><div class="row"><div class="small-12 columns b60"><h2><a href="https://enhanced-telerobotics.github.io/research/VisuohapticPriorExperience/">Learning Visual Force Estimation during Teleoperation of a Surgical Robot</a></h2><p> <a href="https://enhanced-telerobotics.github.io/research/VisuohapticPriorExperience/" title="Learning Visual Force Estimation during Teleoperation of a Surgical Robot"><img src="/images/visuohaptic_thumb.png" class="alignleft" width="300" height="300" alt="Research"></a> Leading commercial robot-assisted minimally invasive surgery (RMIS) platforms such as the da Vinci Surgical System do not provide force feedback to the surgeon. Instead, surgeons rely on visual force estimation to judge the amount of force they apply to tissue. This is a difficult skill that takes a long time to master. Experienced surgeons often report being able to &#39;feel&#39; tissue manipulation forces in their hands. Motivated by the need to accelerate the learning of visual force estimation in RMIS, we investigate the effects of training with force feedback on visual force estimation during teleoperated soft environment manipulation. <a href="https://enhanced-telerobotics.github.io/research/VisuohapticPriorExperience/" title="Read Learning Visual Force Estimation during Teleoperation of a Surgical Robot"><strong>Read More&nbsp;›</strong></a></div></div></div></div></article></div></div><div id="up-to-top" class="row"><div class="small-12 columns" style="text-align: right;"> <a class="iconfont" href="#top-of-page">&#xf108;</a></div></div><footer id="footer-content" class="bg-grau"><div id="subfooter"><nav class="row"><section id="subfooter-left" class="small-12 medium-6 columns credits"><p> © Zonghe Chua at Case Western Reserve University <br> made with <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> based on <a href="http://phlow.github.io/feeling-responsive/">Feeling Responsive</a>.</section><section id="subfooter-right" class="small-12 medium-6 columns"><ul class="inline-list social-icons"></ul></section></nav></div></footer><script src="https://enhanced-telerobotics.github.io/assets/js/javascript.min.js"></script>
